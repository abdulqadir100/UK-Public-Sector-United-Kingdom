{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import json\n",
    "pd.set_option(\"display.max_column\",None)\n",
    "import nibabel\n",
    "from torchsample.modules import ModuleTrainer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"Train.csv\")\n",
    "test_set = pd.read_csv(\"Test.csv\")\n",
    "submission = pd.read_csv(\"SampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.type.value_counts().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_set = pd.concat([train_set.drop([\"type\"],axis=1),test_set],axis=0)\n",
    "all_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val_test, y_train, y_val_test = train_test_split(train_set.tweet,train_set.type,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = x_train\n",
    "#train_label = y_train.replace({\"sexual_violence\":0,'Physical_violence':1,'emotional_violence':2,'Harmful_Traditional_practice':3,'economic_violence':4})\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = x_val_test\n",
    "#val_label = y_val_test.replace({\"sexual_violence\":0,'Physical_violence':1,'emotional_violence':2,'Harmful_Traditional_practice':3,'economic_violence':4})\n",
    "val_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer,MBartTokenizer\n",
    "\n",
    "tokenizer = MBartTokenizer.from_pretrained(\"facebook/mbart-large-en-ro\")\n",
    "\n",
    "def token_counter(text, tokenizer):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "tok_len = all_set.tweet.apply(lambda x : token_counter(x, tokenizer))\n",
    "max(list(tok_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_max_length = 169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_links(text):\n",
    "    to_remove = ['\\r','\\n',',',';',':','.']\n",
    "    \n",
    "    out = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    for token in to_remove:\n",
    "        out = out.replace(token, '')\n",
    "    \n",
    "    return re.sub(' +', ' ', out.lower()) #Remove duplicate spaces\n",
    "\n",
    "def tokenize(text, tokenizer):\n",
    "    return tokenizer.encode(text, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = train_set.apply(remove_links)\n",
    "train_set = train_set.apply((lambda x : tokenize(x, tokenizer)))\n",
    "\n",
    "#val_set = val_set.apply(remove_links)\n",
    "val_set = val_set.apply((lambda x : tokenize(x, tokenizer)))\n",
    "\n",
    "\n",
    "#test_set.tweet = test_set.tweet.apply(remove_links)\n",
    "test_set.tweet = test_set.tweet.apply((lambda x : tokenize(x, tokenizer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574      [6561, 111, 70, 453, 2750, 29892, 297, 163, 50...\n",
       "28131    [87, 509, 137802, 4488, 619, 25133, 74, 87, 50...\n",
       "28560    [4865, 2174, 4, 764, 1902, 29892, 297, 163, 32...\n",
       "6286     [191096, 22936, 46389, 136, 13416, 4049, 5, 27...\n",
       "36291    [4263, 87, 36802, 5154, 4, 764, 17688, 538, 12...\n",
       "                               ...                        \n",
       "6265     [2646, 1119, 2750, 29892, 297, 163, 159399, 43...\n",
       "11284    [18852, 759, 40304, 3445, 17669, 83, 103383, 1...\n",
       "38158    [23972, 5773, 398, 13319, 3714, 163, 566, 959,...\n",
       "860      [6, 72731, 64, 132191, 647, 63026, 112, 29892,...\n",
       "15795    [1061, 87, 48948, 1660, 91755, 37838, 5111, 12...\n",
       "Name: tweet, Length: 27755, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['sexual_violence'],\n",
       "       ['sexual_violence'],\n",
       "       ['sexual_violence'],\n",
       "       ...,\n",
       "       ['sexual_violence'],\n",
       "       ['sexual_violence'],\n",
       "       ['sexual_violence']], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(val_label,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = torch.FloatTensor(train_set), torch.FloatTensor(train_label)\n",
    "test_x = torch.FloatTensor(test_set.tweet)\n",
    "valid_x, valid_y = torch.FloatTensor(val_set.reset_index(drop=True)),torch.FloatTensor(val_label.reset_index(drop=True))\n",
    "\n",
    "\n",
    "\n",
    "train_data = TensorDataset(train_x, train_y)\n",
    "valid_data = TensorDataset(valid_x, valid_y)\n",
    "#test_data = TensorDataset(test_x, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle =True)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=valid_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_x,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random,os\n",
    "    import numpy as np \n",
    "    import torch \n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministics =True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROBERTAClassifier(torch.nn.Module):\n",
    "    def __init__(self, dropout_rate=0.3):\n",
    "        super(ROBERTAClassifier, self).__init__()\n",
    "        self.e = nn.Embedding(59114,38400)\n",
    "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
    "        self.lstm = nn.LSTM(38400, 419, 2,\n",
    "                    batch_first = True, dropout = 0.3)\n",
    "        self.l1 = torch.nn.Linear(419,100)\n",
    "        #self.bn1 = torch.nn.LayerNorm(50)\n",
    "        #self.l2 = torch.nn.Linear(100, 30)\n",
    "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l3 = torch.nn.Linear(100, 5)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        x = self.e(input_ids)\n",
    "        x = self.d1(x[:, -1])\n",
    "        x, h = self.lstm(x.view(1,1,-1))\n",
    "        x = self.l1(x)\n",
    "        #x = self.l1(x.view(1,-1))\n",
    "        #x = self.bn1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.d1(x[:, -1])\n",
    "        x = self.l3(x)\n",
    "\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train mosdel\n",
    "seed_everything(42)\n",
    "#model = ROBERTAClassifier()\n",
    "# Biuld the model\n",
    "D = 419\n",
    "model = nn.Sequential(nn.Embedding(59114,300),\n",
    "                     nn.LSTM(300,64,batch_first=True),\n",
    "                     nn.Dropout(0.2),\n",
    "                     nn.Linear(419,250),\n",
    "                     nn.Linear(250,200),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(200,5))\n",
    "                     #nn.Tanh(),\n",
    "                     #nn.Linear(50,5))\n",
    "\n",
    "\n",
    "\n",
    "#loss and optimization\n",
    "craterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "#stuffs to store \n",
    "train_losses = np.zeros(n_epochs)\n",
    "test_losses = np.zeros(n_epochs)\n",
    "\n",
    "for it in range(n_epochs):\n",
    "    train_loss = []\n",
    "    for inputs,targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        #reshape the input\n",
    "        #inputs = inputs.view(-1,419)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward pass\n",
    "        outputs = model(inputs.type(torch.long))\n",
    "        loss = craterion(outputs,targets.type(torch.LongTensor))\n",
    "        \n",
    "        #backward and optimize\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        \n",
    "    train_loss = np.mean(train_loss)\n",
    "    #for test\n",
    "    test_loss = []\n",
    "    \n",
    "    for inputs,targets in val_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        #reshape the input\n",
    "        #inputs = inputs.view(-1,419)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward pass\n",
    "        outputs = model(inputs.type(torch.long))\n",
    "        loss = craterion(outputs,targets.type(torch.LongTensor))\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "    test_loss = np.mean(test_loss)\n",
    "    \n",
    "    \n",
    "    #save lossess\n",
    "    train_losses[it] = train_loss\n",
    "    test_losses[it] = test_loss\n",
    "        \n",
    "        \n",
    "    \n",
    "    print(f' {it+1}/{n_epochs}, Loss:{train_loss:4f}, Val_loss:{test_loss}')   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unsqueeze(targets,dim =1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses,label=\"Train_losses\")\n",
    "plt.plot(test_losses, label = \"Test_losses\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_correct = 0\n",
    "n_total = 0\n",
    "for inputs, targets in train_loader:\n",
    "    #move data to GPU\n",
    "    inputs, targets =  inputs.to(device),targets.to(device)\n",
    "    #reshape\n",
    "    \n",
    "    inputs = inputs.view(-1,419)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    _,prediction = torch.max(outputs, 1)\n",
    "    \n",
    "    #update counts\n",
    "    \n",
    "    n_correct += (prediction == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "    \n",
    "train_acc = n_correct/n_total\n",
    "\n",
    "n_correct = 0\n",
    "n_total = 0\n",
    "for inputs, targets in val_loader:\n",
    "    #move data to GPU\n",
    "    inputs, targets =  inputs.to(device),targets.to(device)\n",
    "    #reshape\n",
    "    \n",
    "    inputs = inputs.view(-1,419)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    _,prediction = torch.max(outputs, 1)\n",
    "    \n",
    "    #update counts\n",
    "    \n",
    "    n_correct += (prediction == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "    \n",
    "test_acc = n_correct/n_total\n",
    "\n",
    "print(f' Train_Acc:{train_acc},Test_Acc:{test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []\n",
    "for inputs in test_loader:\n",
    "    #move data to GPU\n",
    "    inputs =  inputs.to(device)\n",
    "    #reshape\n",
    "    \n",
    "    inputs = inputs.view(-1,419)\n",
    "    outputs = model(inputs)\n",
    "    _,prediction = torch.max(outputs, 1)\n",
    "    predict.append(prediction.detach().tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predict,columns=[\"type\"])\n",
    "pred = df.replace({0:\"sexual_violence\",1:'Physical_violence',2:'emotional_violence',3:'Harmful_Traditional_practice',4:'economic_violence'})\n",
    "idd = submission.Tweet_ID\n",
    "df = pd.concat([idd,pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.type.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submissionpp.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
